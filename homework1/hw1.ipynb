{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **HW1: Regression**\n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement two regression models to predict the Systolic blood pressure (SBP) of a patient. You will need to implement **both Matrix Inversion and Gradient Descent**.\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implement one regression model to predict the SBP of multiple patients in a different way than the basic part. You can choose **either** of the two methods for this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# **1. Basic Part (55%)**\n",
        "In the first part, you need to implement the regression to predict SBP from the given DBP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EVqWlB-DTF"
      },
      "source": [
        "## 1.1 Matrix Inversion Method (25%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_mi.csv**\n",
        "*   Print your coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "### *Import Packages*\n",
        "\n",
        "> Note: You **cannot** import any other package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "### *Global attributes*\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_basic_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_basic_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_basic_mi.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFC-cvqIcYK"
      },
      "source": [
        "You can add your own global attributes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "### *Load the Input File*\n",
        "First, load the basic input file **hw1_basic_training.csv** and **hw1_basic_testing.csv**\n",
        "\n",
        "Input data would be stored in *training_datalist* and *testing_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "  testing_datalist = np.array(list(csv.reader(csvfile)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "### *Implement the Regression Model*\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "#### Step 1: Split Data\n",
        "Split data in *training_datalist* into training dataset and validation dataset\n",
        "* Validation dataset is used to validate your own model without the testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def SplitData(debug):\n",
        "  #分成training和validation\n",
        "  data = training_datalist[1:]\n",
        "\n",
        "\n",
        "  #分割dataset\n",
        "  split_ratio = 0.8\n",
        "  number_samples = len(data)\n",
        "\n",
        "\n",
        "  train_number_samples = int(split_ratio * number_samples)\n",
        "  if(debug==True):\n",
        "    print(f\"train_number_samples = {train_number_samples}\")\n",
        "\n",
        "  training_data = data[:train_number_samples]\n",
        "  validation_data = data[train_number_samples:]\n",
        "\n",
        "  #轉換成numpy格式\n",
        "  training_data = np.array(training_data)\n",
        "  validation_data = np.array(validation_data)\n",
        "\n",
        "  return training_data, validation_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "#### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def PreprocessData(debug, data):\n",
        "\n",
        "  #basic part沒有missing data\n",
        "  #但有幾筆資料明顯不合理，可以從圖片中看出\n",
        "  #這邊的預處理要替換過於不合理的資料\n",
        "  dbp = [int(row[0]) for row in data]\n",
        "  sbp = [int(row[1]) for row in data]\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"dbp before =  {dbp}\")\n",
        "\n",
        "  threshold = 2.0\n",
        "\n",
        "  # 使用平均值來填\n",
        "  dbp_mean = np.nanmean(dbp)\n",
        "  dbp_std = np.nanstd(dbp)\n",
        "  dbp = [val if not np.isnan(val) and abs(val - dbp_mean) <= threshold * dbp_std else dbp_mean for val in dbp]\n",
        "  dbp = np.array(dbp)\n",
        "\n",
        "  sbp_mean = np.nanmean(sbp)\n",
        "  sbp_std = np.nanstd(sbp)\n",
        "  sbp = [val if not np.isnan(val) and abs(val - sbp_mean) <= threshold * sbp_std else sbp_mean for val in sbp]\n",
        "  sbp = np.array(sbp)\n",
        "\n",
        "\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"dbp_mean =  {dbp_mean}\")\n",
        "    print(f\"dbp_std =  {dbp_std}\")\n",
        "    print(f\"sbp_mean =  {sbp_mean}\")\n",
        "    print(f\"sbp_std =  {sbp_std}\")\n",
        "    number_samples = len(data)\n",
        "    print(\"number of samples = \" + str(number_samples))\n",
        "\n",
        "\n",
        "  #視覺化\n",
        "  if(debug == True):\n",
        "    #X = [int(row[0]) for row in new_data]\n",
        "    #Y = [int(row[1]) for row in new_data]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(dbp, sbp, alpha=0.5)\n",
        "    plt.title('dbp vs sbp')\n",
        "    plt.xlabel('dbp')\n",
        "    plt.ylabel('sbp')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "  return dbp, sbp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Matrix Inversion to finish this part\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "def MatrixInversion(debug, Xl_dbp, Y_sbp):\n",
        "  w0 = 70.0\n",
        "  w1 = 0.0 #dbp\n",
        "\n",
        "  new_intercept_value = 1.0\n",
        "\n",
        "  X = np.column_stack((np.full(Xl_dbp.shape, new_intercept_value), Xl_dbp))\n",
        "\n",
        "  w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_sbp)\n",
        "  w0, w1 = w[0], w[1]\n",
        "\n",
        "\n",
        "  return w0, w1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*\n",
        "The final *output_datalist* should look something like this\n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def MakePrediction(debug, w0, w1):\n",
        "\n",
        "  test_data = testing_datalist[1:]\n",
        "  X_test = [int(row[0]) for row in test_data]\n",
        "\n",
        "  X_test = np.column_stack((np.ones(len(X_test)), X_test))\n",
        "\n",
        "  # 預測\n",
        "  sbp_predicted = w0 + w1 * X_test[:, 1]\n",
        "  sbp_predicted = np.round(sbp_predicted).astype(int)\n",
        "\n",
        "  if(debug==True):\n",
        "    print(\"sbp_predicted = \", sbp_predicted)\n",
        "\n",
        "  return sbp_predicted\n",
        "\n",
        "\n",
        "def MAPE(debug, w, X1_dbp, Y_sbp):\n",
        "\n",
        "  X1_dbp = np.column_stack((np.ones(len(X1_dbp)), X1_dbp))\n",
        "\n",
        "  Y_pred = w[0] + w[1] * X1_dbp[:, 1]\n",
        "  Y_pred = np.round(Y_pred).astype(int)\n",
        "\n",
        "  n = len(Y_sbp)\n",
        "  mape = (1 / n) * np.sum(np.abs((Y_sbp - Y_pred) / Y_sbp)) * 100\n",
        "\n",
        "  # print\n",
        "  if(debug == True):\n",
        "    print(\"MAPE：\", mape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iCL92EPKOFIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d989b2f-60a9-4542-9929-36bfea5647fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9140180543173676 54.038797158228704\n",
            "MAPE： 5.617740912398577\n",
            "sbp_predicted =  [140 131 130 146 111 145 137 137 132 126 125 128 119 125 139 134 151 140\n",
            " 142 148]\n"
          ]
        }
      ],
      "source": [
        "# 分割資料\n",
        "training_data, validation_data = SplitData(False)\n",
        "\n",
        "#print(f\"training data len = {len(training_data)}\")\n",
        "#print(f\"Validation data len = {len(validation_data)}\")\n",
        "\n",
        "# 預處理資料\n",
        "dbp, sbp = PreprocessData(False, training_data)\n",
        "dbp_val, sbp_val = PreprocessData(False, validation_data)\n",
        "\n",
        "\n",
        "# 跑模型計算\n",
        "w0, w1 = MatrixInversion(False, dbp,  sbp)\n",
        "\n",
        "# 印出weights\n",
        "print(w1, w0)\n",
        "\n",
        "# 測試MAPE\n",
        "mape_value = MAPE(True, [w0, w1], dbp_val, sbp_val)\n",
        "\n",
        "# 預測\n",
        "output_datalist = MakePrediction(True, w0, w1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "### *Write the Output File*\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow([row])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3WOhglA9ML"
      },
      "source": [
        "## 1.2 Gradient Descent Method (30%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_gd.csv**\n",
        "*   Output your coefficient update in a csv file **hw1_basic_coefficient.csv**\n",
        "*   Print your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkMqa_xjXhEv"
      },
      "source": [
        "### *Global attributes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wNZtRWUeXpEu"
      },
      "outputs": [],
      "source": [
        "output_dataroot = 'hw1_basic_gd.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "coefficient_output_dataroot = 'hw1_basic_coefficient.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "\n",
        "coefficient_output = [] # Your coefficient update during gradient descent\n",
        "                   # Should be a (number of iterations * number_of coefficient) matrix\n",
        "                   # The format of each row should be ['w0', 'w1', ...., 'wn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5DeHxdLdai3"
      },
      "source": [
        "Your own global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "_2IO5tYSdaFd"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "  testing_datalist = np.array(list(csv.reader(csvfile)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVBLT1aqXuW0"
      },
      "source": [
        "### *Implement the Regression Model*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecPWpcOnXhCZ"
      },
      "source": [
        "#### Step 1: Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1PEf_qGvYHu0"
      },
      "outputs": [],
      "source": [
        "def SplitData(debug):\n",
        "  #分成training和validation\n",
        "  data = training_datalist[1:]\n",
        "\n",
        "\n",
        "  #分割dataset\n",
        "  split_ratio = 0.8\n",
        "  number_samples = len(data)\n",
        "\n",
        "\n",
        "  train_number_samples = int(split_ratio * number_samples)\n",
        "  if(debug==True):\n",
        "    print(f\"train_number_samples = {train_number_samples}\")\n",
        "\n",
        "  training_data = data[:train_number_samples]\n",
        "  validation_data = data[train_number_samples:]\n",
        "\n",
        "  #轉換成numpy格式\n",
        "  training_data = np.array(training_data)\n",
        "  validation_data = np.array(validation_data)\n",
        "\n",
        "  return training_data, validation_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSoPDPKX56w"
      },
      "source": [
        "#### Step 2: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uLTXOWRwYHiS"
      },
      "outputs": [],
      "source": [
        "def PreprocessData(debug, data):\n",
        "\n",
        "  #basic part沒有missing data\n",
        "  #但有幾筆資料明顯不合理，可以從圖片中看出\n",
        "  #這邊的預處理要替換過於不合理的資料\n",
        "  dbp = [int(row[0]) for row in data]\n",
        "  sbp = [int(row[1]) for row in data]\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"dbp before =  {dbp}\")\n",
        "\n",
        "  threshold = 2.0\n",
        "\n",
        "  # 使用平均值來填\n",
        "  dbp_mean = np.nanmean(dbp)\n",
        "  dbp_std = np.nanstd(dbp)\n",
        "  dbp = [val if not np.isnan(val) and abs(val - dbp_mean) <= threshold * dbp_std else dbp_mean for val in dbp]\n",
        "  dbp = np.array(dbp)\n",
        "\n",
        "  sbp_mean = np.nanmean(sbp)\n",
        "  sbp_std = np.nanstd(sbp)\n",
        "  sbp = [val if not np.isnan(val) and abs(val - sbp_mean) <= threshold * sbp_std else sbp_mean for val in sbp]\n",
        "  sbp = np.array(sbp)\n",
        "\n",
        "\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"dbp_mean =  {dbp_mean}\")\n",
        "    print(f\"dbp_std =  {dbp_std}\")\n",
        "    print(f\"sbp_mean =  {sbp_mean}\")\n",
        "    print(f\"sbp_std =  {sbp_std}\")\n",
        "    number_samples = len(data)\n",
        "    print(\"number of samples = \" + str(number_samples))\n",
        "\n",
        "\n",
        "  #視覺化\n",
        "  if(debug == True):\n",
        "    #X = [int(row[0]) for row in new_data]\n",
        "    #Y = [int(row[1]) for row in new_data]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(dbp, sbp, alpha=0.5)\n",
        "    plt.title('dbp vs sbp')\n",
        "    plt.xlabel('dbp')\n",
        "    plt.ylabel('sbp')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "  return dbp, sbp\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_y82gXX6a-"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Gradient Descent to finish this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-635Ee00YHTE"
      },
      "outputs": [],
      "source": [
        "def GradientDescent(debug, learning_rate, num_iterations, X1_dbp, Y_sbp):\n",
        "  #初始weights\n",
        "  w0 = 50.0\n",
        "  w1 = 0.0 #dbp\n",
        "\n",
        "\n",
        "  coefficient = []\n",
        "\n",
        "  #iteration訓練\n",
        "  for iteration in range(num_iterations):\n",
        "    coefficient.append([w0, w1])\n",
        "\n",
        "    #計算預測值\n",
        "    Y_pred = w0 + X1_dbp * w1\n",
        "\n",
        "    # training loss\n",
        "    train_loss = np.mean((Y_sbp - Y_pred) ** 2)\n",
        "\n",
        "\n",
        "    # 計算loss function gradient\n",
        "    gradient_w0 = -np.mean(Y_sbp - Y_pred)\n",
        "    gradient_w1 = -np.mean((Y_sbp - Y_pred) * X1_dbp)\n",
        "\n",
        "\n",
        "    # 更新参数\n",
        "    w0 = w0 - learning_rate * gradient_w0\n",
        "    w1 = w1 - learning_rate * gradient_w1\n",
        "\n",
        "\n",
        "\n",
        "    # print結果\n",
        "    if(debug==True):\n",
        "      print(f\"Iteration {iteration}: Train Loss = {train_loss}, coefficients = {w0, w1}\")\n",
        "\n",
        "\n",
        "\n",
        "  # 打印最终的模型参数\n",
        "  if(debug==True):\n",
        "    print(\"最终的模型参数：\")\n",
        "    print(f\"w0 = {w0}\")\n",
        "    print(f\"w1 = {w1}\")\n",
        "\n",
        "\n",
        "\n",
        "  return w0, w1, coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLuPxs2ZX21S"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "\n",
        "Make prediction of testing dataset and store the values in *output_datalist*\n",
        "The final *output_datalist* should look something like this\n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP\n",
        "\n",
        "Remember to also store your coefficient update in *coefficient_output*\n",
        "The final *coefficient_output* should look something like this\n",
        "> [ [1, 0, 3, 5], ... , [0.1, 0.3, 0.2, 0.5] ] where each row contains the [w0, w1, ..., wn] of your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8pnNDlQeYGtE"
      },
      "outputs": [],
      "source": [
        "def MakePrediction(debug, w0, w1):\n",
        "\n",
        "  test_data = testing_datalist[1:]\n",
        "  X_test = [int(row[0]) for row in test_data]\n",
        "\n",
        "  X_test = np.column_stack((np.ones(len(X_test)), X_test))\n",
        "\n",
        "  # 預測\n",
        "  sbp_predicted = w0 + w1 * X_test[:, 1]\n",
        "  sbp_predicted = np.round(sbp_predicted).astype(int)\n",
        "\n",
        "  if(debug==True):\n",
        "    print(\"sbp_predicted = \", sbp_predicted)\n",
        "\n",
        "  return sbp_predicted\n",
        "\n",
        "\n",
        "def MAPE(debug, w, X1_dbp, Y_sbp):\n",
        "\n",
        "  X1_dbp = np.column_stack((np.ones(len(X1_dbp)), X1_dbp))\n",
        "\n",
        "  Y_pred = w[0] + w[1] * X1_dbp[:, 1]\n",
        "  Y_pred = np.round(Y_pred).astype(int)\n",
        "\n",
        "  n = len(Y_sbp)\n",
        "  mape = (1 / n) * np.sum(np.abs((Y_sbp - Y_pred) / Y_sbp)) * 100\n",
        "\n",
        "  # print\n",
        "  if(debug == True):\n",
        "    print(\"MAPE：\", mape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScbxxMAYAgZ"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "90EisOc7YG-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6996b44-2bf0-431e-e9ef-cdc5514a13f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9618903711182225 50.01241816065527\n",
            "coefficient_output = [[50.0, 0.0], [50.00790401108058, 0.6639540043241295], [50.0103590436974, 0.8696128223159314], [50.011126262229595, 0.9333152960169667], [50.01137068250423, 0.9530469747253534], [50.011453166674734, 0.9591587562609438], [50.011485491328834, 0.9610517921717942], [50.011502279120755, 0.9616380770537184], [50.01151425437309, 0.9618195974859888], [50.01152473893097, 0.9618757426509742], [50.01153476173165, 0.9618930529884313], [50.01154464148712, 0.9618983342882255], [50.011554476918, 0.9618998896092772], [50.011564298602885, 0.961900290813404], [50.01157411601345, 0.9619003345314947], [50.01158393208354, 0.961900267518942], [50.0115937477219, 0.9619001662079112], [50.01160356321003, 0.9619000542731674], [50.01161337863511, 0.9618999390479384], [50.011623194024146, 0.9618998228036821], [50.011633009385505, 0.9618997062439799], [50.011642824721775, 0.961899589586765], [50.011652640033766, 0.961899472899542], [50.01166245532172, 0.9618993562032204], [50.01167227058572, 0.9618992395042768], [50.01168208582578, 0.9618991228047173], [50.01169190104192, 0.9618990061051635], [50.011701716234136, 0.9618988894058078], [50.011711531402426, 0.9618987727067098], [50.0117213465468, 0.9618986560078878], [50.01173116166725, 0.9618985393093477], [50.011740976763775, 0.9618984226110912], [50.01175079183638, 0.9618983059131189], [50.01176060688506, 0.9618981892154309], [50.01177042190982, 0.9618980725180274], [50.01178023691066, 0.9618979558209083], [50.01179005188757, 0.9618978391240736], [50.01179986684057, 0.9618977224275234], [50.01180968176964, 0.9618976057312575], [50.01181949667479, 0.961897489035276], [50.01182931155602, 0.9618973723395791], [50.01183912641333, 0.9618972556441664], [50.01184894124671, 0.9618971389490383], [50.01185875605618, 0.9618970222541945], [50.01186857084172, 0.9618969055596351], [50.01187838560334, 0.9618967888653602], [50.01188820034104, 0.9618966721713698], [50.01189801505482, 0.9618965554776637], [50.01190782974468, 0.961896438784242], [50.011917644410616, 0.9618963220911048], [50.01192745905263, 0.9618962053982519], [50.011937273670725, 0.9618960887056834], [50.0119470882649, 0.9618959720133995], [50.01195690283515, 0.9618958553213999], [50.01196671738148, 0.9618957386296847], [50.0119765319039, 0.9618956219382538], [50.01198634640239, 0.9618955052471075], [50.011996160876954, 0.9618953885562456], [50.012005975327604, 0.961895271865668], [50.01201578975433, 0.9618951551753748], [50.01202560415714, 0.9618950384853661], [50.01203541853602, 0.9618949217956418], [50.01204523289099, 0.9618948051062018], [50.012055047222034, 0.9618946884170463], [50.01206486152916, 0.9618945717281752], [50.012074675812364, 0.9618944550395885], [50.01208449007165, 0.9618943383512862], [50.01209430430701, 0.9618942216632683], [50.01210411851846, 0.9618941049755348], [50.01211393270599, 0.9618939882880858], [50.01212374686959, 0.961893871600921], [50.01213356100928, 0.9618937549140407], [50.01214337512504, 0.9618936382274448], [50.01215318921689, 0.9618935215411333], [50.01216300328482, 0.9618934048551062], [50.012172817328825, 0.9618932881693635], [50.012182631348914, 0.9618931714839051], [50.01219244534508, 0.9618930547987312], [50.01220225931733, 0.9618929381138417], [50.01221207326566, 0.9618928214292365], [50.012221887190066, 0.9618927047449157], [50.012231701090556, 0.9618925880608794], [50.01224151496713, 0.9618924713771274], [50.01225132881978, 0.9618923546936599], [50.01226114264851, 0.9618922380104767], [50.01227095645333, 0.961892121327578], [50.01228077023422, 0.9618920046449635], [50.012290583991195, 0.9618918879626335], [50.01230039772425, 0.9618917712805879], [50.01231021143339, 0.9618916545988266], [50.012320025118605, 0.9618915379173498], [50.012329838779905, 0.9618914212361575], [50.01233965241729, 0.9618913045552493], [50.01234946603075, 0.9618911878746256], [50.01235927962029, 0.9618910711942863], [50.01236909318592, 0.9618909545142315], [50.012378906727626, 0.9618908378344609], [50.01238872024542, 0.9618907211549748], [50.01239853373929, 0.9618906044757729], [50.01240834720924, 0.9618904877968555]]\n",
            "MAPE： 5.516657449908472\n",
            "sbp_predicted =  [140 131 130 147 110 145 138 138 132 126 125 128 118 125 139 135 152 140\n",
            " 142 149]\n"
          ]
        }
      ],
      "source": [
        "# 每個function第一個參數是debug，設True代表要看debug資訊\n",
        "# 分割資料\n",
        "training_data, validation_data = SplitData(False)\n",
        "\n",
        "\n",
        "# 預處理資料\n",
        "dbp, sbp = PreprocessData(False, training_data)\n",
        "dbp_val, sbp_val = PreprocessData(False, validation_data)\n",
        "\n",
        "#學習速率與iterations\n",
        "learning_rate = 0.0001\n",
        "num_iterations = 100\n",
        "\n",
        "# 跑模型計算\n",
        "w0, w1, coefficient_output = GradientDescent(False, learning_rate, num_iterations, dbp, sbp)\n",
        "\n",
        "# 印出weights\n",
        "print(w1, w0)\n",
        "\n",
        "print(f\"coefficient_output = {coefficient_output}\")\n",
        "\n",
        "# 測試MAPE\n",
        "mape_value = MAPE(True, [w0, w1], dbp_val, sbp_val)\n",
        "\n",
        "# 預測\n",
        "output_datalist = MakePrediction(True, w0, w1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1DpV_HcYFpl"
      },
      "source": [
        "### *Write the Output File*\n",
        "\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "**Write the coefficient update to csv**\n",
        "> Format: 'w0', 'w1', ..., 'wn'\n",
        ">*   The number of columns is based on your number of coefficient\n",
        ">*   The number of row is based on your number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NLSHgpDvDXNI"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow([row])\n",
        "\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in coefficient_output:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# **2. Advanced Part (40%)**\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions of multiple patients SBP.\n",
        "\n",
        "You can choose **either** Matrix Inversion or Gradient Descent method.\n",
        "\n",
        "The training data will be in **hw1_advanced_training.csv** and the testing data will be in **hw1_advanced_testing.csv**.\n",
        "\n",
        "Output your prediction in **hw1_advanced.csv**\n",
        "\n",
        "Notice:\n",
        "> You cannot import any other package other than those given\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnvh19XuwapG"
      },
      "source": [
        "### Input the training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "v66HUClZcxaE"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_advanced_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_advanced_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_advanced.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 220 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60njLgbkwapH"
      },
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RJIfFk76wapH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8afbf96-518b-41e5-f465-893b3130fde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "average MAPE = 10.414305482335003\n",
            "[152, 154, 161, 150, 162, 151, 147, 157, 146, 162, 157, 154, 160, 160, 153, 148, 159, 160, 146, 151, 147, 141, 140, 138, 143, 141, 146, 142, 145, 139, 142, 141, 139, 140, 152, 144, 141, 139, 149, 139, 114, 110, 115, 116, 117, 108, 114, 123, 114, 113, 119, 113, 123, 123, 116, 126, 129, 126, 127, 114, 151, 152, 152, 154, 143, 143, 143, 150, 150, 152, 153, 149, 144, 149, 151, 150, 148, 151, 146, 146, 126, 126, 127, 127, 125, 126, 125, 124, 126, 126, 124, 126, 126, 127, 125, 127, 126, 125, 126, 126, 131, 132, 131, 134, 131, 132, 136, 134, 130, 132, 136, 133, 132, 129, 134, 132, 130, 129, 134, 132, 119, 116, 117, 119, 119, 117, 115, 116, 117, 117, 117, 119, 118, 120, 119, 117, 117, 119, 118, 116, 124, 123, 127, 124, 124, 122, 124, 131, 130, 127, 119, 124, 124, 123, 124, 123, 123, 131, 129, 127, 134, 134, 134, 135, 135, 135, 135, 134, 134, 135, 134, 136, 136, 135, 135, 134, 134, 135, 134, 134, 125, 127, 122, 127, 128, 129, 123, 126, 128, 124, 130, 127, 128, 130, 125, 128, 123, 123, 124, 128, 126, 125, 124, 124, 126, 127, 125, 130, 130, 123, 128, 125, 130, 127, 128, 127, 126, 122, 123, 124]\n"
          ]
        }
      ],
      "source": [
        "#key: 用多項參數來預測sbp，沒有dbp可以用\n",
        "#就先試著用sbp = w0 + w1 * temperature + w2 * heartrate + w3 * resprate + w4 * o2sat吧\n",
        "\n",
        "#1. 先做資料讀取\n",
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "  testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "#print(testing_datalist)\n",
        "\n",
        "#2. 預處理資料，先用1位病人的資料當範例就好，想想看怎麼處理空的資料\n",
        "#遇到空值的資料填成平均值，outliers也填成平均值\n",
        "#應該先不用分validation set\n",
        "\n",
        "#subject_id = []\n",
        "#charttime = []\n",
        "#temperature = []\n",
        "#heartrate = []\n",
        "#resprate = []\n",
        "#o2sat = []\n",
        "#sbp = []\n",
        "\n",
        "#分成training和validation\n",
        "def ad_SplitData(debug, id, ratio):\n",
        "  data = training_datalist[1:]\n",
        "\n",
        "  #指定病人\n",
        "  selected_subject_id = str(id)\n",
        "  selected_data = [row for row in data if row[0] == selected_subject_id]\n",
        "\n",
        "\n",
        "  #分割dataset\n",
        "  split_ratio = ratio\n",
        "  number_samples = len(selected_data)\n",
        "\n",
        "\n",
        "  train_number_samples = int(split_ratio * number_samples)\n",
        "  if(debug==True):\n",
        "    print(f\"train_number_samples = {train_number_samples}\")\n",
        "\n",
        "  training_data = selected_data[:train_number_samples]\n",
        "  validation_data = selected_data[train_number_samples:]\n",
        "\n",
        "  #轉換成numpy格式\n",
        "  training_data = np.array(training_data)\n",
        "  validation_data = np.array(validation_data)\n",
        "\n",
        "  return training_data, validation_data\n",
        "\n",
        "\n",
        "def ad_PreprocessData(debug, data):\n",
        "  #header = training_datalist[0]\n",
        "  #data = training_datalist[1:]\n",
        "\n",
        "  subject_id = [int(row[0]) for row in data]\n",
        "  charttime = [str(row[1]) for row in data]\n",
        "  temperature = [float(row[2]) if row[2] else np.nan for row in data]\n",
        "  heartrate = [float(row[3]) if row[3] else np.nan for row in data]\n",
        "  resprate = [float(row[4]) if row[4] else np.nan for row in data]\n",
        "  o2sat = [float(row[5]) if row[5] else np.nan for row in data]\n",
        "  sbp = [float(row[6]) if row[6] else np.nan for row in data]\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"temperature before =  {temperature}\")\n",
        "\n",
        "  threshold = 2.0\n",
        "\n",
        "  # 使用平均值來填\n",
        "  temperature_mean = np.nanmean(temperature)\n",
        "  temperature_std = np.nanstd(temperature)\n",
        "  #temperature = [val if not np.isnan(val) else temperature_mean for val in temperature]\n",
        "  temperature = [val if not np.isnan(val) and abs(val - temperature_mean) <= threshold * temperature_std else temperature_mean for val in temperature]\n",
        "  temperature = np.array(temperature)\n",
        "\n",
        "  heartrate_mean = np.nanmean(heartrate)\n",
        "  heartrate_std = np.nanstd(heartrate)\n",
        "  heartrate = [val if not np.isnan(val) and abs(val - heartrate_mean) <= threshold * heartrate_std else heartrate_mean for val in heartrate]\n",
        "  heartrate = np.array(heartrate)\n",
        "\n",
        "  resprate_mean = np.nanmean(resprate)\n",
        "  resprate_std = np.nanstd(resprate)\n",
        "  resprate = [val if not np.isnan(val) and abs(val - resprate_mean) <= threshold * resprate_std else resprate_mean for val in resprate]\n",
        "  resprate = np.array(resprate)\n",
        "\n",
        "  o2sat_mean = np.nanmean(o2sat)\n",
        "  o2sat_std = np.nanstd(o2sat)\n",
        "  o2sat = [val if not np.isnan(val) and abs(val - o2sat_mean) <= threshold * o2sat_std else o2sat_mean for val in o2sat]\n",
        "  o2sat = np.array(o2sat)\n",
        "\n",
        "  sbp_mean = np.nanmean(sbp)\n",
        "  sbp_std = np.nanstd(sbp)\n",
        "  sbp = [val if not np.isnan(val) and abs(val - sbp_mean) <= threshold * sbp_std else sbp_mean for val in sbp]\n",
        "  sbp = np.array(sbp)\n",
        "\n",
        "\n",
        "\n",
        "  if(debug == True):\n",
        "    print(f\"temperature_mean =  {temperature_mean}\")\n",
        "    print(f\"heartrate_mean =  {heartrate_mean}\")\n",
        "    print(f\"resprate_mean =  {resprate_mean}\")\n",
        "    print(f\"o2sat_mean =  {o2sat_mean}\")\n",
        "    print(f\"sbp_mean =  {sbp_mean}\")\n",
        "    print(f\"temperature after =  {temperature}\")\n",
        "    number_samples = len(data)\n",
        "    print(\"number of samples = \" + str(number_samples))\n",
        "\n",
        "  return temperature, heartrate, resprate, o2sat, sbp\n",
        "\n",
        "\n",
        "#3. Gradient descent\n",
        "def GradientDescent(debug, learning_rate, num_iterations, X1_temperature, X2_heartrate, X3_resprate, X4_o2sat, Y_sbp):\n",
        "  #初始weights\n",
        "  w0 = 70.0\n",
        "  w1 = 0.0 #temperature\n",
        "  w2 = 0.0 #heartrate\n",
        "  w3 = 0.0 # resprate\n",
        "  w4 = 0.0 #o2sat\n",
        "\n",
        "\n",
        "  #coefficients = []\n",
        "\n",
        "  #iteration訓練\n",
        "  for iteration in range(num_iterations):\n",
        "    #coefficients.append([w0, w1])\n",
        "\n",
        "    #計算預測值\n",
        "    #Y_pred = w0 + X1_temperature*w1 + X2_heartrate*w2 + X3_resprate*w3 + X4_o2sat*w4\n",
        "    Y_pred = w0 + X2_heartrate*w2 + X3_resprate*w3\n",
        "\n",
        "    # training loss\n",
        "    train_loss = np.mean((Y_sbp - Y_pred) ** 2)\n",
        "\n",
        "\n",
        "    # 計算loss function gradient\n",
        "    gradient_w0 = -np.mean(Y_sbp - Y_pred)\n",
        "    ##gradient_w1 = -np.mean((Y_sbp - Y_pred) * X1_temperature)\n",
        "    gradient_w2 = -np.mean((Y_sbp - Y_pred) * X2_heartrate)\n",
        "    gradient_w3 = -np.mean((Y_sbp - Y_pred) * X3_resprate)\n",
        "    ##gradient_w4 = -np.mean((Y_sbp - Y_pred) * X4_o2sat)\n",
        "\n",
        "    # 更新参数\n",
        "    w0 = w0 - learning_rate * gradient_w0\n",
        "    ##w1 = w1 - learning_rate * gradient_w1\n",
        "    w2 = w2 - learning_rate * gradient_w2\n",
        "    w3 = w3 - learning_rate * gradient_w3\n",
        "    ##w4 = w4 - learning_rate * gradient_w4\n",
        "\n",
        "    # print結果\n",
        "    if(debug==True):\n",
        "      print(f\"Iteration {iteration}: Train Loss = {train_loss}, coefficients = {w0, w1, w2, w3, w4}\")\n",
        "\n",
        "\n",
        "  return w0, w1, w2, w3, w4\n",
        "\n",
        "\n",
        "# matrix inversion\n",
        "def MatrixInversion(debug, X1_temperature, X2_heartrate, X3_resprate, X4_o2sat, Y_sbp, id):\n",
        "  w0 = 70.0\n",
        "  w1 = 0.0 #temperature\n",
        "  w2 = 0.0 #heartrate\n",
        "  w3 = 0.0 # resprate\n",
        "  w4 = 0.0 #o2sat\n",
        "\n",
        "  new_intercept_value = 1.0\n",
        "\n",
        "  #X = np.column_stack((np.ones(len(X1_temperature)), X1_temperature, X2_heartrate, X3_resprate, X4_o2sat))\n",
        "\n",
        "  #X = np.column_stack((np.full(X1_temperature.shape, new_intercept_value), X1_temperature, X2_heartrate, X3_resprate, X4_o2sat))\n",
        "  if(id == 14699420 or id == 15437705):\n",
        "    X = np.column_stack((np.full(X1_temperature.shape, new_intercept_value), X2_heartrate*2 , X3_resprate))\n",
        "  else:\n",
        "    X = np.column_stack((np.full(X1_temperature.shape, new_intercept_value), X2_heartrate , X3_resprate))\n",
        "\n",
        "\n",
        "  w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_sbp)\n",
        "  w0, w2, w3 = w[0], w[1], w[2]\n",
        "\n",
        "\n",
        "  return w0, w1, w2, w3, w4\n",
        "\n",
        "#視覺化\n",
        "def DrawData(temperature, heartrate, resprate, o2sat, sbp):\n",
        "  #temperature vs sbp\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(temperature, sbp, alpha=0.5)\n",
        "  plt.title('temperature vs sbp')\n",
        "  plt.xlabel('temperature')\n",
        "  plt.ylabel('sbp')\n",
        "  plt.grid(True)\n",
        "\n",
        "  #heartrate vs sbp\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(heartrate, sbp, alpha=0.5)\n",
        "  plt.title('heartrate vs sbp')\n",
        "  plt.xlabel('heartrate')\n",
        "  plt.ylabel('sbp')\n",
        "  plt.grid(True)\n",
        "\n",
        "  #resprate vs sbp\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(resprate, sbp, alpha=0.5)\n",
        "  plt.title('resprate vs sbp')\n",
        "  plt.xlabel('resprate')\n",
        "  plt.ylabel('sbp')\n",
        "  plt.grid(True)\n",
        "\n",
        "  #o2sat vs sbp\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(o2sat, sbp, alpha=0.5)\n",
        "  plt.title('o2sat vs sbp')\n",
        "  plt.xlabel('o2sat')\n",
        "  plt.ylabel('sbp')\n",
        "  plt.grid(True)\n",
        "\n",
        "\n",
        "\n",
        "#計算MAPE\n",
        "def MAPE(debug, w, X1_temperature, X2_heartrate, X3_resprate, X4_o2sat, Y_sbp):\n",
        "\n",
        "  X1_temperature = np.column_stack((np.ones(len(X1_temperature)), X1_temperature))\n",
        "  X2_heartrate = np.column_stack((np.ones(len(X2_heartrate)), X2_heartrate))\n",
        "  X3_resprate = np.column_stack((np.ones(len(X3_resprate)), X3_resprate))\n",
        "  X4_o2sat = np.column_stack((np.ones(len(X4_o2sat)), X4_o2sat))\n",
        "\n",
        "  #預測\n",
        "  Y_pred = w[0] + w[1] * X1_temperature[:, 1] + w[2] * X2_heartrate[:, 1] + w[3] * X3_resprate[:, 1] + w[4] * X4_o2sat[:, 1]\n",
        "  #Y_pred = np.round(Y_pred).astype(int)\n",
        "\n",
        "  n = len(Y_sbp)\n",
        "  mape = (1 / n) * np.sum(np.abs((Y_sbp - Y_pred) / Y_sbp)) * 100\n",
        "\n",
        "  # 打印 MAPE\n",
        "  if(debug == True):\n",
        "    print(\"MAPE：\", mape)\n",
        "\n",
        "  return mape\n",
        "\n",
        "# 預測\n",
        "def ad_MakePrediction(debug, w, patients):\n",
        "\n",
        "  data = testing_datalist[1:]\n",
        "  sbp_pred = []\n",
        "\n",
        "  for id in patients:\n",
        "    #指定病人\n",
        "    selected_subject_id = str(id)\n",
        "    selected_data = [row for row in data if row[0] == selected_subject_id]\n",
        "\n",
        "    temperature = [float(row[2]) if row[2] else 0.0 for row in selected_data]\n",
        "    heartrate = [float(row[3]) if row[3] else 0.0 for row in selected_data]\n",
        "    resprate = [float(row[4]) if row[4] else 0.0 for row in selected_data]\n",
        "    o2sat = [float(row[5]) if row[5] else 0.0 for row in selected_data]\n",
        "    sbp = [float(row[6]) if row[6] else 0.0 for row in selected_data]\n",
        "\n",
        "    temperature = np.array(temperature)\n",
        "    heartrate = np.array(heartrate)\n",
        "    resprate = np.array(resprate)\n",
        "    o2sat = np.array(o2sat)\n",
        "    sbp = np.array(sbp)\n",
        "\n",
        "\n",
        "    X1_temperature = np.column_stack((np.ones(len(temperature)), temperature))\n",
        "    X2_heartrate = np.column_stack((np.ones(len(heartrate)), heartrate))\n",
        "    X3_resprate = np.column_stack((np.ones(len(resprate)), resprate))\n",
        "    X4_o2sat = np.column_stack((np.ones(len(o2sat)), o2sat))\n",
        "\n",
        "    #預測\n",
        "    Y_pred = w[id][0] + w[id][1] * X1_temperature[:, 1] + w[id][2] * X2_heartrate[:, 1] + w[id][3] * X3_resprate[:, 1] + w[id][4] * X4_o2sat[:, 1]\n",
        "    Y_pred = np.round(Y_pred).astype(int)\n",
        "\n",
        "    sbp_pred.append(Y_pred)\n",
        "\n",
        "    if(debug==True):\n",
        "      print(\"Y_pred = \", Y_pred)\n",
        "\n",
        "  sbp_predicted = [item for sublist in sbp_pred for item in sublist]\n",
        "  #sbp_predicted = np.array(sbp_predicted)\n",
        "\n",
        "  return sbp_predicted\n",
        "\n",
        "\n",
        "# 啟用 --------------------------------------------------------------------------\n",
        "\n",
        "#學習速率與iterations\n",
        "learning_rate = 0.0001\n",
        "num_iterations = 10000\n",
        "\n",
        "\n",
        "patients = [11526383, 12923910, 14699420, 15437705, 15642911, 16298357, 17331999\n",
        ", 17593883, 18733920, 18791093, 19473413]\n",
        "\n",
        "MAPEs = []\n",
        "Weights = dict()\n",
        "\n",
        "# 測試用\n",
        "#training_data, validation_data = ad_SplitData(False, 15437705, 0.8)\n",
        "#temperature, heartrate, resprate, o2sat, sbp = ad_PreprocessData(False, training_data)\n",
        "#DrawData(temperature, heartrate, resprate, o2sat, sbp)\n",
        "\n",
        "Debug = False\n",
        "\n",
        "for id in patients:\n",
        "\n",
        "  # 分割資料\n",
        "  training_data, validation_data = ad_SplitData(False, id, 0.8)\n",
        "\n",
        "  if(Debug == True):\n",
        "    print(f\"----------------patient { id }-----------------\")\n",
        "    print(f\"training data len = {len(training_data)}\")\n",
        "    print(f\"Validation data len = {len(validation_data)}\")\n",
        "\n",
        "\n",
        "  # 預處理資料\n",
        "  temperature, heartrate, resprate, o2sat, sbp = ad_PreprocessData(False, training_data)\n",
        "  temperature_val, heartrate_val, resprate_val, o2sat_val, sbp_val = ad_PreprocessData(False, validation_data)\n",
        "\n",
        "  # 畫出圖片來看\n",
        "  #DrawData(temperature, heartrate, resprate, o2sat, sbp)\n",
        "\n",
        "  # 跑模型計算\n",
        "  #w0, w1, w2, w3, w4 = GradientDescent(False, learning_rate, num_iterations, temperature, heartrate, resprate, o2sat, sbp)\n",
        "  w0, w1, w2, w3, w4 = MatrixInversion(True, temperature, heartrate, resprate, o2sat, sbp, id)\n",
        "\n",
        "  # 測試MAPE\n",
        "  mape_value = MAPE(False, [w0, w1, w2, w3, w4], temperature_val, heartrate_val, resprate_val, o2sat_val, sbp_val)\n",
        "\n",
        "  MAPEs.append(mape_value)\n",
        "  # print\n",
        "\n",
        "  if(Debug == True):\n",
        "    print(\"最终的模型参数：\")\n",
        "    print(f\"w0 = {w0}\")\n",
        "    print(f\"w1 = {w1}\")\n",
        "    print(f\"w2 = {w2}\")\n",
        "    print(f\"w3 = {w3}\")\n",
        "    print(f\"w4 = {w4}\")\n",
        "\n",
        "    print(f\"MAPE: {mape_value}\")\n",
        "\n",
        "  Weights[id] = [w0, w1, w2, w3, w4]\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "print(f\"average MAPE = {sum(MAPEs) / len(MAPEs)}\")\n",
        "\n",
        "\n",
        "# 預測\n",
        "#temperature_test, heartrate_test, resprate_test, o2sat_test, sbp_test = ad_PreprocessData(False, testing_datalist[1:])\n",
        "output_datalist = ad_MakePrediction(False, Weights, patients)\n",
        "print(output_datalist)\n",
        "#print(Weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFyjdc5BwapH"
      },
      "source": [
        "### Output your Prediction\n",
        "\n",
        "> your filename should be **hw1_advanced.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "25VMbyJZwapH"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow([row])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgCJU7FPeJL"
      },
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered\n",
        "*   Summarize your work and your reflections\n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEE53_MPf4W"
      },
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}