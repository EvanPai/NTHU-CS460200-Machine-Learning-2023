{"cells":[{"cell_type":"markdown","id":"Wrjxt74b46is","metadata":{"id":"Wrjxt74b46is"},"source":[]},{"cell_type":"markdown","id":"OGWc1HS95GKZ","metadata":{"id":"OGWc1HS95GKZ"},"source":["# Trainer\n",">* You can follow your work in HW3 to complete this file"]},{"cell_type":"code","execution_count":1,"id":"73846386","metadata":{"collapsed":true,"id":"73846386"},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from Loss.ipynb\n","importing Jupyter notebook from Model.ipynb\n","importing Jupyter notebook from Utils.ipynb\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","import math\n","\n","import import_ipynb\n","from Loss import *\n","from Model import *\n","from Utils import random_mini_batches"]},{"cell_type":"code","execution_count":2,"id":"7cff696d","metadata":{"id":"7cff696d"},"outputs":[],"source":["def trainer(model, config, x_train_pca, y_train):\n","    losses = []\n","    # Loop (gradient descent)\n","    for i in range(0, config.num_iterations):\n","        mini_batches = random_mini_batches(x_train_pca, y_train, config.batch_size)\n","        loss = 0\n","        for batch in mini_batches:\n","            x_batch, y_batch = batch\n","\n","            # forward\n","            AL = model.forward(x_batch)\n","\n","            # compute loss\n","            if config.loss_function == 'cross_entropy':\n","                loss += compute_CCE_loss(AL, y_batch)\n","            elif config.loss_function == 'focal_loss':\n","                loss += compute_focal_loss(AL, y_batch, config.alpha, config.gamma)\n","\n","            # backward\n","            dA_prev = model.backward(AL, y_batch)\n","            # update\n","            model.update(config.learning_rate)\n","\n","        loss /= len(mini_batches)\n","        losses.append(loss)\n","        if config.print_loss and i % config.print_freq == 0:\n","            print (\"Loss after iteration %i: %f\" %(i, loss))\n","\n","\n","    # plot the loss\n","    plt.figure(figsize=(4, 2))\n","    plt.plot(np.squeeze(losses))\n","    plt.ylabel('loss')\n","    plt.xlabel('iterations (per hundreds)')\n","    plt.title(\"Learning rate =\" + str(config.learning_rate))\n","    plt.show()\n","    ### END CODE HERE ###"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11.5 ('biopsy')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"bc07a8c6aa785ccbb5cb0815abffaffb139b111aca417c4ffe9bf221bae76ba2"}}},"nbformat":4,"nbformat_minor":5}
